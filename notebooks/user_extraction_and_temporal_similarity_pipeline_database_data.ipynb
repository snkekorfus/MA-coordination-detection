{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to create temporal similarity based on the data in the MongoDB database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from dtaidistance import dtw\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract relevant users from the clusters in the textClust mongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_users_from_clusters(source_uuid, cluster_id, timestamp):\n",
    "    connection = MongoClient(f\"mongodb://localhost:27017/\")\n",
    "    db = connection.textclustDB\n",
    "    \n",
    "    # Extract all tweets of a cluster from the MongoDB database\n",
    "    textids = db[f\"mc_{source_uuid}\"].find_one(\n",
    "        {\"id\": cluster_id},\n",
    "        sort=[(\"timestamp\", -1)],\n",
    "        projection={\n",
    "            \"_id\": 0,\n",
    "            \"textids\": 1\n",
    "            }\n",
    "    )\n",
    "    \n",
    "    # Extract the relevant users\n",
    "    users = db[f\"texts_{source_uuid}\"].find(\n",
    "        {\n",
    "            \"$and\": [\n",
    "                {\"general.text_id\": {\n",
    "                        \"$in\": textids[\"textids\"]\n",
    "                    }\n",
    "                },\n",
    "                {\"$or\": [\n",
    "                    {\"general.time\": {\n",
    "                        \"$lte\": datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S\")\n",
    "                        }\n",
    "                    },\n",
    "                    {\"general.time\": {\n",
    "                        \"$lte\": timestamp.replace(\"T\", \" \")\n",
    "                        }\n",
    "                    }\n",
    "                ]}\n",
    "            ]\n",
    "        },\n",
    "        sort=[(\"general.time\", -1)],\n",
    "        projection = {\n",
    "            \"_id\": 0,\n",
    "            \"user\": \"$specific.user\"\n",
    "        }\n",
    "    ).limit(5000)\n",
    "    users = pd.DataFrame([user['user'] for user in users])\n",
    "    return users.drop_duplicates([\"id_str\"], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = extract_relevant_users_from_clusters(\"8273444c-abdd-4410-829a-970846ebd00e\", 52525, \"2022-02-25T22:41:49\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach to use the MongoDB database to acquire the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load last tweets of the users in the cluster from the MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets_per_user(source_uuid, user, timestamp):\n",
    "    connection = MongoClient(f\"mongodb://localhost:27017/\")\n",
    "    db = connection.textclustDB\n",
    "    data =  db[f\"texts_{source_uuid}\"].find(\n",
    "        {\"$and\": [\n",
    "            {\"specific.user.id\": user['id']}, \n",
    "            {\"$or\": [\n",
    "                    {\"general.time\": {\n",
    "                        \"$lte\": datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S\")\n",
    "                        }\n",
    "                    },\n",
    "                    {\"general.time\": {\n",
    "                        \"$lte\": timestamp.replace(\"T\", \" \")\n",
    "                        }\n",
    "                    }\n",
    "                ]}\n",
    "        ]},\n",
    "        projection={\n",
    "            \"_id\": 0,\n",
    "            \"user_screen_name\": \"$specific.user.screen_name\",\n",
    "            \"user_id\": \"$specific.user.id_str\",\n",
    "            \"id\": \"$specific.user.id\",\n",
    "            \"text\": \"$general.text\",\n",
    "            \"created_at\": \"$general.time\"\n",
    "        }\n",
    "        )\n",
    "    return pd.DataFrame(list(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the method for every user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(columns=[\"user_screen_name\", \"user_id\", \"id\", \"text\", \"created_at\"])\n",
    "\n",
    "for _, user in tqdm(users.iterrows(), total=len(users)):\n",
    "    response = extract_tweets_per_user(\"8273444c-abdd-4410-829a-970846ebd00e\", user, \"2022-02-25T22:41:49\")\n",
    "    tweets = pd.concat([tweets, response], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt timestamp types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets['created_at'] = tweets['created_at'].values.astype('datetime64[m]')\n",
    "tweet = tweets.astype({'created_at': 'datetime64[m]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 24 hour time frame based on the date of the newest tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = tweets[\"created_at\"].max()\n",
    "end = start - datetime.timedelta(days=1)\n",
    "tweets = tweets[tweets[\"created_at\"] > end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe representing the user behavior as a time-series with 1 minute steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tweet_time_series_for_user(user_df, end_timestamp, start_timestamp):\n",
    "    end = end_timestamp.replace(second=0, microsecond=0)\n",
    "    start = start_timestamp.replace(second=0, microsecond=0)\n",
    "    date_ranges = pd.date_range(start=start, end=end, freq='1min')\n",
    "    bins = pd.cut(user_df['created_at'], bins=date_ranges, right=False, labels=[x for x in range(0,len(date_ranges)-1)])\n",
    "    groups = user_df.groupby(['user_screen_name', bins])\n",
    "    return groups.size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = create_tweet_time_series_for_user(tweets, tweets[\"created_at\"].max(), tweets[\"created_at\"].min())\n",
    "\n",
    "# Filter users with less than 10 tweets in a timespan of 1 day\n",
    "# This is done because users with only a few tweets will have a low distance\n",
    "# to other users as their are not many warping operations needed\n",
    "time_series = time_series[time_series.sum(axis=1) > 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similarity matrix for users with DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dtw_distance(x, y):\n",
    "    distance = dtw.distance(x.astype('double'), y.astype('double'), window=2, use_c=True)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(squareform(pdist(time_series, metric=calculate_dtw_distance)), columns=time_series.index.values, index=time_series.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform distances into similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.values.flatten())\n",
    "np.fill_diagonal(result.values, max(result.values.flatten()))\n",
    "similarity = 1 - result / max(result.values.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the timeseries of users in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.loc['XXX'].plot(figsize=(8,5), xlabel=\"Time bins in minutes\", fontsize=14)\n",
    "plt.xlabel('Time bins in minutes', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.loc['XXX'].plot(figsize=(8,5), xlabel=\"Time bins in minutes\", fontsize=14)\n",
    "plt.xlabel('Time bins in minutes', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similarity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(similarity)\n",
    "\n",
    "F = G.copy()\n",
    "threshold = 0.9\n",
    "F.remove_edges_from([(n1, n2) for n1, n2, w in F.edges(data=\"weight\") if w < threshold])\n",
    "F.remove_nodes_from(list(nx.isolates(F)))\n",
    "fig = plt.figure(1, figsize=(30, 20), dpi=60)\n",
    "nx.draw(F, with_labels=True, node_size=1000, font_size=24)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample random edge\n",
    "\n",
    "This is good for getting two connected users in the graph to inspect their profiles manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(F.edges(), 1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eabb0453c7dc57e3cda88eb3c18a07491dfe4a6a097c369f6ee5831a0349db6d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('Masterarbeit_Code-DnaPFa3Q': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
